{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9998d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2492fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/feast/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c01eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df = data.loc[:,data.columns!='Outcome']\n",
    "target_df = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "506e6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.date_range(end = pd.Timestamp.now(),\n",
    "                           periods = len(data),freq = 'D').to_frame(name = 'event_timestamp', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aafd9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df = pd.concat(objs = [predictors_df, timestamps], axis = 1)\n",
    "target_df = pd.concat(objs = [target_df, timestamps], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61e9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLen = len(data)\n",
    "idsList = list(range(dataLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a896e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = pd.DataFrame(data = idsList, columns = ['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd234278",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df = pd.concat(objs = [predictors_df, patient_ids], axis = 1)\n",
    "target_df = pd.concat(objs = [target_df, patient_ids], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b5f38a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\feast\\\\feature_repo'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3e0504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df.to_parquet(path='C:/feast/feature_repo/data/predictors_df.parquet')\n",
    "target_df.to_parquet(path='C:/feast/feature_repo/data/target_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f0b9225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-10 15:17:54.338338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-11 15:17:54.338338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-12 15:17:54.338338</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-13 15:17:54.338338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-14 15:17:54.338338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome            event_timestamp  patient_id\n",
       "0        1 2020-12-10 15:17:54.338338           0\n",
       "1        0 2020-12-11 15:17:54.338338           1\n",
       "2        1 2020-12-12 15:17:54.338338           2\n",
       "3        0 2020-12-13 15:17:54.338338           3\n",
       "4        1 2020-12-14 15:17:54.338338           4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b64581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a new Feast repository in C:\\feast\\feature_repo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!feast init feature_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6166101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\feast\\feature_repo\n"
     ]
    }
   ],
   "source": [
    "cd C:\\feast\\feature_repo\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b3c21b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated feature view predictors_df_feature_view\n",
      "\tbatch_source: name: \"predictors_stats_source\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"event_timestamp\"\n",
      "created_timestamp_column: \"created\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  uri: \"C:/feast/feature_repo/data/predictors_df.parquet\"\n",
      "}\n",
      " -> name: \"predictors_stats_source\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"event_timestamp\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  uri: \"C:/feast/feature_repo/data/predictors_df.parquet\"\n",
      "}\n",
      "\n",
      "Updated feature view target_df_feature_view\n",
      "\tbatch_source: name: \"target_df_feature\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"event_timestamp\"\n",
      "created_timestamp_column: \"created\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  uri: \"C:/feast/feature_repo/data/target_df.parquet\"\n",
      "}\n",
      " -> name: \"target_df_feature\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"event_timestamp\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  uri: \"C:/feast/feature_repo/data/target_df.parquet\"\n",
      "}\n",
      "\n",
      "\n",
      "No changes to infrastructure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91832\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\infra\\offline_stores\\file_source.py:161: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
      "  schema = ParquetDataset(path).schema.to_arrow_schema()\n"
     ]
    }
   ],
   "source": [
    "!feast apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35a27752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91832\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\feature_store.py:1182: RuntimeWarning: Saving dataset is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "SavedDatasetLocationAlreadyExists",
     "evalue": "Saved dataset location data/diabetes_dataset.parquet already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSavedDatasetLocationAlreadyExists\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 23\u001b[0m\n\u001b[0;32m      7\u001b[0m entity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(path \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/feast/feature_repo/data/target_df.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m training_data \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_historical_features(\n\u001b[0;32m     10\u001b[0m entity_df \u001b[38;5;241m=\u001b[39m entity_df,\n\u001b[0;32m     11\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m                ]\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_saved_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiabetes_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSavedDatasetFileStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/diabetes_dataset.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\usage.py:299\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mtraceback \u001b[38;5;241m=\u001b[39m _trace_to_log(traceback)\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traceback:\n\u001b[1;32m--> 299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\usage.py:288\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m ctx\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mupdate(attrs)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mexception:\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;66;03m# exception was already recorded\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\feature_store.py:1207\u001b[0m, in \u001b[0;36mFeatureStore.create_saved_dataset\u001b[1;34m(self, from_, name, storage, tags, feature_service, allow_overwrite)\u001b[0m\n\u001b[0;32m   1204\u001b[0m dataset\u001b[38;5;241m.\u001b[39mmin_event_timestamp \u001b[38;5;241m=\u001b[39m from_\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mmin_event_timestamp\n\u001b[0;32m   1205\u001b[0m dataset\u001b[38;5;241m.\u001b[39mmax_event_timestamp \u001b[38;5;241m=\u001b[39m from_\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mmax_event_timestamp\n\u001b[1;32m-> 1207\u001b[0m \u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_overwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_overwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_retrieval_job(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_provider()\u001b[38;5;241m.\u001b[39mretrieve_saved_dataset(\n\u001b[0;32m   1211\u001b[0m         config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, dataset\u001b[38;5;241m=\u001b[39mdataset\n\u001b[0;32m   1212\u001b[0m     )\n\u001b[0;32m   1213\u001b[0m )\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mapply_saved_dataset(dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject, commit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\infra\\offline_stores\\file.py:96\u001b[0m, in \u001b[0;36mFileRetrievalJob.persist\u001b[1;34m(self, storage, allow_overwrite)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Check if the specified location already exists.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_overwrite \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(storage\u001b[38;5;241m.\u001b[39mfile_options\u001b[38;5;241m.\u001b[39muri):\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SavedDatasetLocationAlreadyExists(location\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mfile_options\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m     98\u001b[0m filesystem, path \u001b[38;5;241m=\u001b[39m FileSource\u001b[38;5;241m.\u001b[39mcreate_filesystem_and_path(\n\u001b[0;32m     99\u001b[0m     storage\u001b[38;5;241m.\u001b[39mfile_options\u001b[38;5;241m.\u001b[39muri,\n\u001b[0;32m    100\u001b[0m     storage\u001b[38;5;241m.\u001b[39mfile_options\u001b[38;5;241m.\u001b[39ms3_endpoint_override,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mSavedDatasetLocationAlreadyExists\u001b[0m: Saved dataset location data/diabetes_dataset.parquet already exists."
     ]
    }
   ],
   "source": [
    "from feast import FeatureStore\n",
    "from feast.infra.offline_stores.file_source import SavedDatasetFileStorage\n",
    "from feast.infra.offline_stores.bigquery_source import SavedDatasetBigQueryStorage\n",
    "\n",
    "store = FeatureStore(repo_path='.')\n",
    "\n",
    "entity_df = pd.read_parquet(path ='C:/feast/feature_repo/data/target_df.parquet')\n",
    "\n",
    "training_data = store.get_historical_features(\n",
    "entity_df = entity_df,\n",
    "    features = [\n",
    "        \"predictors_df_feature_view:Pregnancies\",\n",
    "        \"predictors_df_feature_view:Glucose\",\n",
    "        \"predictors_df_feature_view:BloodPressure\",\n",
    "        \"predictors_df_feature_view:SkinThickness\",\n",
    "        \"predictors_df_feature_view:Insulin\",\n",
    "        \"predictors_df_feature_view:BMI\",\n",
    "        \"predictors_df_feature_view:DiabetesPedigreeFunction\",\n",
    "        \"predictors_df_feature_view:Age\",\n",
    "               ]\n",
    ")\n",
    "\n",
    "dataset = store.create_saved_dataset(\n",
    "from_=training_data,\n",
    "    name = \"diabetes_dataset\",\n",
    "    storage = SavedDatasetFileStorage('data/diabetes_dataset.parquet')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ccee8ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.0-cp310-cp310-win_amd64.whl (8.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ------------------------------------- 298.0/298.0 kB 28.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\91832\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.0-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "     --------------------------------------- 42.5/42.5 MB 90.2 kB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0 scipy-1.10.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a71749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91832\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feast\\feature_store.py:1235: RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91832\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "# Importing dependencies\n",
    "from feast import FeatureStore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "\n",
    "# Getting our FeatureStore\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "# Retrieving the saved dataset and converting it to a DataFrame\n",
    "training_df = store.get_saved_dataset(name=\"diabetes_dataset\").to_df()\n",
    "\n",
    "# Separating the features and labels\n",
    "y = training_df['Outcome']\n",
    "X = training_df.drop(\n",
    "    labels=['Outcome', 'event_timestamp', \"patient_id\"], \n",
    "    axis=1)\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# Creating and training LogisticRegression\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X=X_train[sorted(X_train)], y=y_train)\n",
    "\n",
    "# Saving the model\n",
    "dump(value=reg, filename=\"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1bd4770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views to \u001b[1m\u001b[32m2023-01-16 17:14:40+05:30\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mpredictors_df_feature_view\u001b[0m from \u001b[1m\u001b[32m2023-01-15 11:44:40+05:30\u001b[0m to \u001b[1m\u001b[32m2023-01-16 17:14:40+05:30\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 102.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mtarget_df_feature_view\u001b[0m from \u001b[1m\u001b[32m2023-01-15 11:44:41+05:30\u001b[0m to \u001b[1m\u001b[32m2023-01-16 22:44:40+05:30\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 84.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from feast import FeatureStore\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Getting our FeatureStore\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "store.materialize_incremental(end_date = datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad74abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from feast import FeatureStore\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# Getting our FeatureStore\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "# Defining our features names\n",
    "feast_features = [\n",
    "        \"predictors_df_feature_view:Pregnancies\",\n",
    "        \"predictors_df_feature_view:Glucose\",\n",
    "        \"predictors_df_feature_view:BloodPressure\",\n",
    "        \"predictors_df_feature_view:SkinThickness\",\n",
    "        \"predictors_df_feature_view:Insulin\",\n",
    "        \"predictors_df_feature_view:BMI\",\n",
    "        \"predictors_df_feature_view:DiabetesPedigreeFunction\",\n",
    "        \"predictors_df_feature_view:Age\",\n",
    "    ]\n",
    "\n",
    "# Getting the latest features\n",
    "features = store.get_online_features(\n",
    "    features=feast_features,    \n",
    "    entity_rows=[{\"patient_id\": 767}, {\"patient_id\": 766}]\n",
    ").to_dict()\n",
    "\n",
    "# Converting the features to a DataFrame\n",
    "features_df = pd.DataFrame.from_dict(data=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "836222eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.4</td>\n",
       "      <td>93</td>\n",
       "      <td>0.315</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>766</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>126</td>\n",
       "      <td>0.349</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  Insulin  Pregnancies   BMI  Glucose  DiabetesPedigreeFunction  \\\n",
       "0         767        0            1  30.4       93                     0.315   \n",
       "1         766        0            1  30.1      126                     0.349   \n",
       "\n",
       "   BloodPressure  SkinThickness  Age  \n",
       "0             70             31   23  \n",
       "1             60              0   47  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc76400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "reg = load(\"model.joblib\")\n",
    "predictions = reg.predict(features_df[sorted(features_df.drop(\"patient_id\", axis=1))])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa160214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
